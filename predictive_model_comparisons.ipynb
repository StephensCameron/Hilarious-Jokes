{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf2df38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\"\"\"\n",
    "First we will import the necessary libraries for our analysis.\n",
    "We might also need some functions from our main.py file\n",
    "\"\"\"\n",
    "import main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04ae585f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first get the datasets and split them\n",
    "joke_dataset, train_dataset_full, train_dataset, val_dataset, test_dataset = main.load_and_split_data()\n",
    "\n",
    "# This will split the dataset up into training and test sets and create the necessary input/output pairs\n",
    "selected_indices, complement_indices, JTrain_x, JTrain_y, JTest_x, JTest_y = main.select_train_complement_indices(\n",
    "        joke_dataset, train_dataset_full, train_dataset, val_dataset, test_dataset, cross_validation=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2647d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.3604 - mae: 0.5070 - val_loss: 0.3279 - val_mae: 0.4571\n",
      "Epoch 2/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3394 - mae: 0.4851 - val_loss: 0.3145 - val_mae: 0.4470\n",
      "Epoch 3/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3104 - mae: 0.4735 - val_loss: 0.3025 - val_mae: 0.4378\n",
      "Epoch 4/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3217 - mae: 0.4767 - val_loss: 0.2911 - val_mae: 0.4291\n",
      "Epoch 5/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2839 - mae: 0.4511 - val_loss: 0.2804 - val_mae: 0.4209\n",
      "Epoch 6/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2853 - mae: 0.4519 - val_loss: 0.2702 - val_mae: 0.4128\n",
      "Epoch 7/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2818 - mae: 0.4447 - val_loss: 0.2605 - val_mae: 0.4049\n",
      "Epoch 8/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2600 - mae: 0.4258 - val_loss: 0.2512 - val_mae: 0.3971\n",
      "Epoch 9/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.2563 - mae: 0.4225 - val_loss: 0.2424 - val_mae: 0.3895\n",
      "Epoch 10/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2361 - mae: 0.4038 - val_loss: 0.2339 - val_mae: 0.3819\n",
      "Epoch 11/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2259 - mae: 0.3912 - val_loss: 0.2256 - val_mae: 0.3743\n",
      "Epoch 12/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2254 - mae: 0.3940 - val_loss: 0.2177 - val_mae: 0.3669\n",
      "Epoch 13/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.2083 - mae: 0.3764 - val_loss: 0.2099 - val_mae: 0.3598\n",
      "Epoch 14/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2008 - mae: 0.3703 - val_loss: 0.2024 - val_mae: 0.3524\n",
      "Epoch 15/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1952 - mae: 0.3596 - val_loss: 0.1950 - val_mae: 0.3454\n",
      "Epoch 16/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1883 - mae: 0.3549 - val_loss: 0.1879 - val_mae: 0.3391\n",
      "Epoch 17/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1863 - mae: 0.3564 - val_loss: 0.1811 - val_mae: 0.3331\n",
      "Epoch 18/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1762 - mae: 0.3434 - val_loss: 0.1743 - val_mae: 0.3270\n",
      "Epoch 19/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1563 - mae: 0.3222 - val_loss: 0.1678 - val_mae: 0.3211\n",
      "Epoch 20/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1550 - mae: 0.3206 - val_loss: 0.1614 - val_mae: 0.3153\n",
      "Epoch 21/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1516 - mae: 0.3144 - val_loss: 0.1547 - val_mae: 0.3091\n",
      "Epoch 22/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1341 - mae: 0.2963 - val_loss: 0.1479 - val_mae: 0.3031\n",
      "Epoch 23/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1293 - mae: 0.2917 - val_loss: 0.1410 - val_mae: 0.2969\n",
      "Epoch 24/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1277 - mae: 0.2910 - val_loss: 0.1343 - val_mae: 0.2914\n",
      "Epoch 25/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1240 - mae: 0.2870 - val_loss: 0.1279 - val_mae: 0.2857\n",
      "Epoch 26/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1110 - mae: 0.2695 - val_loss: 0.1215 - val_mae: 0.2793\n",
      "Epoch 27/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1087 - mae: 0.2644 - val_loss: 0.1151 - val_mae: 0.2724\n",
      "Epoch 28/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1055 - mae: 0.2645 - val_loss: 0.1090 - val_mae: 0.2657\n",
      "Epoch 29/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1050 - mae: 0.2630 - val_loss: 0.1029 - val_mae: 0.2587\n",
      "Epoch 30/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0972 - mae: 0.2510 - val_loss: 0.0971 - val_mae: 0.2518\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "train rel error: 0.5319100547941027\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "val rel error: 0.5661832158293368\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0902 - mae: 0.2413\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0971 - mae: 0.2518\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "train residuals: 0.5319100547941027\n",
      "dev residuals: 0.5661832158293368\n",
      "\n",
      "\n",
      "Epoch 1/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.3243 - mae: 0.4762 - val_loss: 0.4692 - val_mae: 0.6032\n",
      "Epoch 2/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3251 - mae: 0.4841 - val_loss: 0.4469 - val_mae: 0.5876\n",
      "Epoch 3/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3330 - mae: 0.4903 - val_loss: 0.4260 - val_mae: 0.5726\n",
      "Epoch 4/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2792 - mae: 0.4440 - val_loss: 0.4072 - val_mae: 0.5589\n",
      "Epoch 5/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2674 - mae: 0.4329 - val_loss: 0.3892 - val_mae: 0.5453\n",
      "Epoch 6/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2648 - mae: 0.4307 - val_loss: 0.3719 - val_mae: 0.5318\n",
      "Epoch 7/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2467 - mae: 0.4095 - val_loss: 0.3547 - val_mae: 0.5178\n",
      "Epoch 8/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2372 - mae: 0.4037 - val_loss: 0.3375 - val_mae: 0.5034\n",
      "Epoch 9/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2209 - mae: 0.3876 - val_loss: 0.3203 - val_mae: 0.4886\n",
      "Epoch 10/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2185 - mae: 0.3809 - val_loss: 0.3035 - val_mae: 0.4735\n",
      "Epoch 11/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2038 - mae: 0.3676 - val_loss: 0.2871 - val_mae: 0.4585\n",
      "Epoch 12/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1870 - mae: 0.3506 - val_loss: 0.2707 - val_mae: 0.4433\n",
      "Epoch 13/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1945 - mae: 0.3581 - val_loss: 0.2542 - val_mae: 0.4278\n",
      "Epoch 14/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1763 - mae: 0.3427 - val_loss: 0.2379 - val_mae: 0.4121\n",
      "Epoch 15/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1667 - mae: 0.3315 - val_loss: 0.2221 - val_mae: 0.3964\n",
      "Epoch 16/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1532 - mae: 0.3152 - val_loss: 0.2058 - val_mae: 0.3794\n",
      "Epoch 17/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1475 - mae: 0.3090 - val_loss: 0.1906 - val_mae: 0.3633\n",
      "Epoch 18/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1417 - mae: 0.3026 - val_loss: 0.1757 - val_mae: 0.3474\n",
      "Epoch 19/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1301 - mae: 0.2908 - val_loss: 0.1612 - val_mae: 0.3313\n",
      "Epoch 20/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1231 - mae: 0.2811 - val_loss: 0.1480 - val_mae: 0.3159\n",
      "Epoch 21/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1209 - mae: 0.2811 - val_loss: 0.1355 - val_mae: 0.3011\n",
      "Epoch 22/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1017 - mae: 0.2555 - val_loss: 0.1245 - val_mae: 0.2874\n",
      "Epoch 23/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1094 - mae: 0.2668 - val_loss: 0.1143 - val_mae: 0.2745\n",
      "Epoch 24/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1031 - mae: 0.2587 - val_loss: 0.1053 - val_mae: 0.2632\n",
      "Epoch 25/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0907 - mae: 0.2405 - val_loss: 0.0973 - val_mae: 0.2533\n",
      "Epoch 26/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0861 - mae: 0.2369 - val_loss: 0.0902 - val_mae: 0.2443\n",
      "Epoch 27/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0799 - mae: 0.2290 - val_loss: 0.0844 - val_mae: 0.2371\n",
      "Epoch 28/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0747 - mae: 0.2205 - val_loss: 0.0790 - val_mae: 0.2304\n",
      "Epoch 29/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0764 - mae: 0.2236 - val_loss: 0.0745 - val_mae: 0.2245\n",
      "Epoch 30/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0708 - mae: 0.2144 - val_loss: 0.0709 - val_mae: 0.2199\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "train rel error: 0.4796612727261075\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "val rel error: 0.3963640378776093\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0682 - mae: 0.2110\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0709 - mae: 0.2199\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "train residuals: 0.4796612727261075\n",
      "dev residuals: 0.3963640378776093\n",
      "\n",
      "\n",
      "Epoch 1/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.4532 - mae: 0.5768 - val_loss: 0.3553 - val_mae: 0.4908\n",
      "Epoch 2/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3935 - mae: 0.5232 - val_loss: 0.3261 - val_mae: 0.4665\n",
      "Epoch 3/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3774 - mae: 0.5175 - val_loss: 0.2995 - val_mae: 0.4444\n",
      "Epoch 4/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3397 - mae: 0.4817 - val_loss: 0.2757 - val_mae: 0.4243\n",
      "Epoch 5/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3170 - mae: 0.4663 - val_loss: 0.2540 - val_mae: 0.4047\n",
      "Epoch 6/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2714 - mae: 0.4257 - val_loss: 0.2344 - val_mae: 0.3869\n",
      "Epoch 7/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2682 - mae: 0.4260 - val_loss: 0.2164 - val_mae: 0.3704\n",
      "Epoch 8/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2624 - mae: 0.4199 - val_loss: 0.2001 - val_mae: 0.3555\n",
      "Epoch 9/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2394 - mae: 0.4019 - val_loss: 0.1852 - val_mae: 0.3415\n",
      "Epoch 10/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1964 - mae: 0.3602 - val_loss: 0.1714 - val_mae: 0.3283\n",
      "Epoch 11/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2045 - mae: 0.3682 - val_loss: 0.1592 - val_mae: 0.3160\n",
      "Epoch 12/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1926 - mae: 0.3574 - val_loss: 0.1480 - val_mae: 0.3042\n",
      "Epoch 13/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1875 - mae: 0.3565 - val_loss: 0.1376 - val_mae: 0.2931\n",
      "Epoch 14/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1825 - mae: 0.3499 - val_loss: 0.1282 - val_mae: 0.2828\n",
      "Epoch 15/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1669 - mae: 0.3323 - val_loss: 0.1197 - val_mae: 0.2732\n",
      "Epoch 16/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1586 - mae: 0.3236 - val_loss: 0.1124 - val_mae: 0.2652\n",
      "Epoch 17/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1297 - mae: 0.2921 - val_loss: 0.1054 - val_mae: 0.2573\n",
      "Epoch 18/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1299 - mae: 0.2930 - val_loss: 0.0992 - val_mae: 0.2501\n",
      "Epoch 19/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1124 - mae: 0.2719 - val_loss: 0.0937 - val_mae: 0.2437\n",
      "Epoch 20/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1293 - mae: 0.2954 - val_loss: 0.0887 - val_mae: 0.2376\n",
      "Epoch 21/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1065 - mae: 0.2679 - val_loss: 0.0844 - val_mae: 0.2324\n",
      "Epoch 22/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1059 - mae: 0.2637 - val_loss: 0.0805 - val_mae: 0.2278\n",
      "Epoch 23/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1042 - mae: 0.2611 - val_loss: 0.0770 - val_mae: 0.2233\n",
      "Epoch 24/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0958 - mae: 0.2497 - val_loss: 0.0742 - val_mae: 0.2198\n",
      "Epoch 25/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0959 - mae: 0.2503 - val_loss: 0.0716 - val_mae: 0.2164\n",
      "Epoch 26/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0918 - mae: 0.2448 - val_loss: 0.0694 - val_mae: 0.2134\n",
      "Epoch 27/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0814 - mae: 0.2298 - val_loss: 0.0674 - val_mae: 0.2104\n",
      "Epoch 28/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0825 - mae: 0.2300 - val_loss: 0.0658 - val_mae: 0.2082\n",
      "Epoch 29/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0774 - mae: 0.2226 - val_loss: 0.0643 - val_mae: 0.2059\n",
      "Epoch 30/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0761 - mae: 0.2218 - val_loss: 0.0629 - val_mae: 0.2041\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "train rel error: 0.4899854280106479\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "val rel error: 0.47206728232457784\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0760 - mae: 0.2221\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0629 - mae: 0.2041\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "train residuals: 0.4899854280106479\n",
      "dev residuals: 0.47206728232457784\n",
      "\n",
      "\n",
      "Epoch 1/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.3409 - mae: 0.4961 - val_loss: 0.3540 - val_mae: 0.5176\n",
      "Epoch 2/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3212 - mae: 0.4768 - val_loss: 0.3297 - val_mae: 0.4973\n",
      "Epoch 3/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3096 - mae: 0.4690 - val_loss: 0.3069 - val_mae: 0.4780\n",
      "Epoch 4/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2642 - mae: 0.4267 - val_loss: 0.2864 - val_mae: 0.4597\n",
      "Epoch 5/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2543 - mae: 0.4134 - val_loss: 0.2669 - val_mae: 0.4421\n",
      "Epoch 6/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2466 - mae: 0.4107 - val_loss: 0.2486 - val_mae: 0.4246\n",
      "Epoch 7/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2172 - mae: 0.3779 - val_loss: 0.2320 - val_mae: 0.4082\n",
      "Epoch 8/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2153 - mae: 0.3800 - val_loss: 0.2161 - val_mae: 0.3921\n",
      "Epoch 9/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2149 - mae: 0.3774 - val_loss: 0.2014 - val_mae: 0.3772\n",
      "Epoch 10/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1839 - mae: 0.3482 - val_loss: 0.1879 - val_mae: 0.3635\n",
      "Epoch 11/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1763 - mae: 0.3386 - val_loss: 0.1753 - val_mae: 0.3504\n",
      "Epoch 12/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1704 - mae: 0.3320 - val_loss: 0.1636 - val_mae: 0.3373\n",
      "Epoch 13/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1567 - mae: 0.3171 - val_loss: 0.1524 - val_mae: 0.3245\n",
      "Epoch 14/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1447 - mae: 0.3063 - val_loss: 0.1421 - val_mae: 0.3123\n",
      "Epoch 15/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1357 - mae: 0.2982 - val_loss: 0.1326 - val_mae: 0.3006\n",
      "Epoch 16/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1268 - mae: 0.2869 - val_loss: 0.1240 - val_mae: 0.2904\n",
      "Epoch 17/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1185 - mae: 0.2798 - val_loss: 0.1161 - val_mae: 0.2813\n",
      "Epoch 18/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1123 - mae: 0.2722 - val_loss: 0.1089 - val_mae: 0.2725\n",
      "Epoch 19/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1083 - mae: 0.2649 - val_loss: 0.1025 - val_mae: 0.2648\n",
      "Epoch 20/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1004 - mae: 0.2575 - val_loss: 0.0965 - val_mae: 0.2577\n",
      "Epoch 21/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0993 - mae: 0.2545 - val_loss: 0.0910 - val_mae: 0.2510\n",
      "Epoch 22/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0884 - mae: 0.2413 - val_loss: 0.0859 - val_mae: 0.2449\n",
      "Epoch 23/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0879 - mae: 0.2407 - val_loss: 0.0813 - val_mae: 0.2392\n",
      "Epoch 24/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0804 - mae: 0.2269 - val_loss: 0.0773 - val_mae: 0.2339\n",
      "Epoch 25/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0793 - mae: 0.2275 - val_loss: 0.0738 - val_mae: 0.2290\n",
      "Epoch 26/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0727 - mae: 0.2200 - val_loss: 0.0706 - val_mae: 0.2243\n",
      "Epoch 27/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0717 - mae: 0.2174 - val_loss: 0.0677 - val_mae: 0.2196\n",
      "Epoch 28/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0756 - mae: 0.2230 - val_loss: 0.0650 - val_mae: 0.2151\n",
      "Epoch 29/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0753 - mae: 0.2210 - val_loss: 0.0629 - val_mae: 0.2111\n",
      "Epoch 30/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0652 - mae: 0.2073 - val_loss: 0.0612 - val_mae: 0.2076\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "train rel error: 0.46148713300309585\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "val rel error: 0.41601539142289345\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0657 - mae: 0.2068\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0612 - mae: 0.2076\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "train residuals: 0.46148713300309585\n",
      "dev residuals: 0.41601539142289345\n",
      "\n",
      "\n",
      "Epoch 1/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.3890 - mae: 0.5353 - val_loss: 0.4110 - val_mae: 0.5670\n",
      "Epoch 2/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.4124 - mae: 0.5530 - val_loss: 0.3875 - val_mae: 0.5489\n",
      "Epoch 3/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3508 - mae: 0.5047 - val_loss: 0.3661 - val_mae: 0.5318\n",
      "Epoch 4/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3276 - mae: 0.4869 - val_loss: 0.3462 - val_mae: 0.5152\n",
      "Epoch 5/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3144 - mae: 0.4752 - val_loss: 0.3277 - val_mae: 0.4992\n",
      "Epoch 6/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2897 - mae: 0.4494 - val_loss: 0.3103 - val_mae: 0.4837\n",
      "Epoch 7/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2758 - mae: 0.4364 - val_loss: 0.2937 - val_mae: 0.4683\n",
      "Epoch 8/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2537 - mae: 0.4199 - val_loss: 0.2780 - val_mae: 0.4537\n",
      "Epoch 9/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2449 - mae: 0.4157 - val_loss: 0.2631 - val_mae: 0.4396\n",
      "Epoch 10/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2283 - mae: 0.3957 - val_loss: 0.2492 - val_mae: 0.4260\n",
      "Epoch 11/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2321 - mae: 0.3990 - val_loss: 0.2358 - val_mae: 0.4122\n",
      "Epoch 12/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2017 - mae: 0.3703 - val_loss: 0.2230 - val_mae: 0.3987\n",
      "Epoch 13/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1975 - mae: 0.3658 - val_loss: 0.2108 - val_mae: 0.3856\n",
      "Epoch 14/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1842 - mae: 0.3494 - val_loss: 0.1994 - val_mae: 0.3731\n",
      "Epoch 15/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1777 - mae: 0.3444 - val_loss: 0.1882 - val_mae: 0.3612\n",
      "Epoch 16/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1589 - mae: 0.3220 - val_loss: 0.1777 - val_mae: 0.3498\n",
      "Epoch 17/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1480 - mae: 0.3089 - val_loss: 0.1679 - val_mae: 0.3389\n",
      "Epoch 18/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1424 - mae: 0.3050 - val_loss: 0.1583 - val_mae: 0.3284\n",
      "Epoch 19/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1334 - mae: 0.2921 - val_loss: 0.1495 - val_mae: 0.3183\n",
      "Epoch 20/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1352 - mae: 0.2944 - val_loss: 0.1410 - val_mae: 0.3086\n",
      "Epoch 21/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1201 - mae: 0.2771 - val_loss: 0.1331 - val_mae: 0.2992\n",
      "Epoch 22/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1133 - mae: 0.2675 - val_loss: 0.1258 - val_mae: 0.2901\n",
      "Epoch 23/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1065 - mae: 0.2603 - val_loss: 0.1188 - val_mae: 0.2814\n",
      "Epoch 24/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0986 - mae: 0.2503 - val_loss: 0.1124 - val_mae: 0.2740\n",
      "Epoch 25/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0967 - mae: 0.2473 - val_loss: 0.1064 - val_mae: 0.2668\n",
      "Epoch 26/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0848 - mae: 0.2317 - val_loss: 0.1011 - val_mae: 0.2603\n",
      "Epoch 27/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0864 - mae: 0.2337 - val_loss: 0.0964 - val_mae: 0.2543\n",
      "Epoch 28/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0785 - mae: 0.2228 - val_loss: 0.0922 - val_mae: 0.2488\n",
      "Epoch 29/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0802 - mae: 0.2288 - val_loss: 0.0883 - val_mae: 0.2434\n",
      "Epoch 30/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0758 - mae: 0.2198 - val_loss: 0.0848 - val_mae: 0.2386\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "train rel error: 0.4783403222244888\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "val rel error: 0.49226935852446463\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0704 - mae: 0.2122\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0848 - mae: 0.2386\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "train residuals: 0.4783403222244888\n",
      "dev residuals: 0.49226935852446463\n",
      "\n",
      "\n",
      "Epoch 1/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.3349 - mae: 0.4882 - val_loss: 0.2706 - val_mae: 0.4179\n",
      "Epoch 2/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3042 - mae: 0.4570 - val_loss: 0.2551 - val_mae: 0.4067\n",
      "Epoch 3/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3139 - mae: 0.4736 - val_loss: 0.2411 - val_mae: 0.3967\n",
      "Epoch 4/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2732 - mae: 0.4310 - val_loss: 0.2283 - val_mae: 0.3877\n",
      "Epoch 5/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2611 - mae: 0.4216 - val_loss: 0.2169 - val_mae: 0.3796\n",
      "Epoch 6/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2521 - mae: 0.4174 - val_loss: 0.2066 - val_mae: 0.3718\n",
      "Epoch 7/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2283 - mae: 0.3978 - val_loss: 0.1975 - val_mae: 0.3647\n",
      "Epoch 8/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2166 - mae: 0.3834 - val_loss: 0.1889 - val_mae: 0.3576\n",
      "Epoch 9/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2066 - mae: 0.3727 - val_loss: 0.1816 - val_mae: 0.3512\n",
      "Epoch 10/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2006 - mae: 0.3682 - val_loss: 0.1746 - val_mae: 0.3451\n",
      "Epoch 11/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1755 - mae: 0.3407 - val_loss: 0.1686 - val_mae: 0.3391\n",
      "Epoch 12/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1773 - mae: 0.3402 - val_loss: 0.1628 - val_mae: 0.3323\n",
      "Epoch 13/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1635 - mae: 0.3276 - val_loss: 0.1580 - val_mae: 0.3261\n",
      "Epoch 14/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1484 - mae: 0.3091 - val_loss: 0.1537 - val_mae: 0.3197\n",
      "Epoch 15/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1531 - mae: 0.3142 - val_loss: 0.1500 - val_mae: 0.3133\n",
      "Epoch 16/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1380 - mae: 0.2947 - val_loss: 0.1467 - val_mae: 0.3078\n",
      "Epoch 17/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1280 - mae: 0.2861 - val_loss: 0.1435 - val_mae: 0.3023\n",
      "Epoch 18/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1139 - mae: 0.2681 - val_loss: 0.1406 - val_mae: 0.2974\n",
      "Epoch 19/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1125 - mae: 0.2671 - val_loss: 0.1378 - val_mae: 0.2928\n",
      "Epoch 20/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1037 - mae: 0.2563 - val_loss: 0.1357 - val_mae: 0.2898\n",
      "Epoch 21/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1038 - mae: 0.2562 - val_loss: 0.1339 - val_mae: 0.2869\n",
      "Epoch 22/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0890 - mae: 0.2362 - val_loss: 0.1324 - val_mae: 0.2839\n",
      "Epoch 23/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0935 - mae: 0.2432 - val_loss: 0.1313 - val_mae: 0.2816\n",
      "Epoch 24/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0925 - mae: 0.2380 - val_loss: 0.1303 - val_mae: 0.2790\n",
      "Epoch 25/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0849 - mae: 0.2321 - val_loss: 0.1286 - val_mae: 0.2760\n",
      "Epoch 26/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0767 - mae: 0.2178 - val_loss: 0.1275 - val_mae: 0.2735\n",
      "Epoch 27/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0747 - mae: 0.2171 - val_loss: 0.1267 - val_mae: 0.2714\n",
      "Epoch 28/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0739 - mae: 0.2158 - val_loss: 0.1261 - val_mae: 0.2702\n",
      "Epoch 29/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0655 - mae: 0.2043 - val_loss: 0.1254 - val_mae: 0.2688\n",
      "Epoch 30/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0720 - mae: 0.2136 - val_loss: 0.1247 - val_mae: 0.2671\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "train rel error: 0.45228250571350676\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "val rel error: 0.6921671036125472\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0645 - mae: 0.2018\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.1247 - mae: 0.2671\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "train residuals: 0.45228250571350676\n",
      "dev residuals: 0.6921671036125472\n",
      "\n",
      "\n",
      "Epoch 1/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.4230 - mae: 0.5433 - val_loss: 0.3689 - val_mae: 0.5374\n",
      "Epoch 2/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.4126 - mae: 0.5354 - val_loss: 0.3484 - val_mae: 0.5208\n",
      "Epoch 3/30\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.3711 - mae: 0.5171"
     ]
    }
   ],
   "source": [
    "# Now let's create a cross-validation routine\n",
    "\n",
    "import time\n",
    "\n",
    "def cross_validate_model(data, selected_indices, complement_indices, n_splits=5):\n",
    "    \"\"\"\n",
    "    Perform k-fold cross-validation on the dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    data (numpy.ndarray): Full dataset.\n",
    "    selected_indices (list): Indices of selected features.\n",
    "    complement_indices (list): Indices of complementary features.\n",
    "    k (int): Number of components for dimensionality reduction.\n",
    "    n_splits (int): Number of folds for cross-validation.\n",
    "    \n",
    "    Returns:\n",
    "    avg_model (numpy.ndarray): Averaged model parameters across all folds.\n",
    "    avg_train_error (float): Average relative error on training sets across all folds.\n",
    "    avg_val_error (float): Average relative error on validation sets across all folds.\n",
    "    avg_loss_training (float): Average loss on training sets across all folds.\n",
    "    avg_loss_validation (float): Average loss on validation sets across all folds.\n",
    "    \"\"\"\n",
    "\n",
    "    k = 2\n",
    "\n",
    "    normalization_factor = 1/10 \n",
    "    data = data * normalization_factor # Normalize the data to be between 0 and 1\n",
    "\n",
    "    kfold = KFold(n_splits=n_splits)\n",
    "\n",
    "    all_relative_errors_training = []\n",
    "    all_relative_errors_validation = []\n",
    "    all_loss_training = []\n",
    "    all_loss_validation = []\n",
    "    all_models = []\n",
    "\n",
    "    for train_index, val_index in kfold.split(data):\n",
    "\n",
    "\n",
    "\n",
    "        X_train, X_val = data[train_index], data[val_index]\n",
    "        JTrain_x = X_train[:, selected_indices]\n",
    "        JTrain_y = X_train[:, complement_indices]\n",
    "        JDev_x = X_val[:, selected_indices]\n",
    "        JDev_y = X_val[:, complement_indices]\n",
    "\n",
    "        mu_x = np.mean(JTrain_x, axis=0)\n",
    "        X_train_centered = JTrain_x - mu_x\n",
    "        X_val_centered = JDev_x - mu_x\n",
    "\n",
    "\n",
    "        U, S, V_T = np.linalg.svd(JTrain_x, full_matrices=False)\n",
    "        U_k = U[:, :k]\n",
    "        S_k = np.diag(S[:k])\n",
    "        V_T_k = V_T[:k, :]\n",
    "\n",
    "        xtrain_reduced = X_train_centered @ V_T_k.T\n",
    "        xtrain_reduced = np.hstack((xtrain_reduced, np.ones((xtrain_reduced.shape[0], 1))))  # Add bias term\n",
    "        x_dev_reduced = X_val_centered @ V_T_k.T\n",
    "        x_dev_reduced = np.hstack((x_dev_reduced, np.ones((x_dev_reduced.shape[0], 1))))  # Add bias term\n",
    "\n",
    "        model = keras.Sequential([\n",
    "            keras.layers.Input(shape=(xtrain_reduced.shape[1],)),\n",
    "            keras.layers.Dense(16, activation=\"relu\"), #kernel_regularizer=keras.regularizers.l2(1e-3)), #what does this do?\n",
    "            keras.layers.Dense(JTrain_y.shape[1], activation=\"linear\")\n",
    "        ])\n",
    "\n",
    "        model.compile(optimizer=\"adam\",\n",
    "                       loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "\n",
    "        model.fit(\n",
    "            xtrain_reduced, JTrain_y,\n",
    "            validation_data=(x_dev_reduced, JDev_y),\n",
    "            epochs=30,\n",
    "            batch_size=8,   # smaller batch size helps with tiny datasets\n",
    "            callbacks=[EarlyStopping(patience=10, restore_best_weights=True)]\n",
    "        )\n",
    "\n",
    "\n",
    "        # time_start = time.time()\n",
    "        # model.fit(xtrain_reduced, JTrain_y, epochs=5, batch_size=32)\n",
    "        # time_end = time.time()\n",
    "        # print(f\"Training time: {time_end - time_start} seconds\")\n",
    "\n",
    "        all_models.append(model)\n",
    "        print(f'train rel error: {np.linalg.norm(model.predict(xtrain_reduced) - JTrain_y, \"fro\") / np.linalg.norm(JTrain_y, \"fro\")}')\n",
    "        all_relative_errors_training.append(np.linalg.norm(model.predict(xtrain_reduced) - JTrain_y, \"fro\") / np.linalg.norm(JTrain_y, \"fro\"))\n",
    "        all_relative_errors_validation.append(np.linalg.norm(model.predict(x_dev_reduced) - JDev_y, \"fro\") / np.linalg.norm(JDev_y, \"fro\"))\n",
    "        print(f'val rel error: {np.linalg.norm(model.predict(x_dev_reduced) - JDev_y, \"fro\") / np.linalg.norm(JDev_y, \"fro\")}')\n",
    "        all_loss_training.append(np.mean(model.evaluate(xtrain_reduced, JTrain_y)))\n",
    "        all_loss_validation.append(np.mean(model.evaluate(x_dev_reduced, JDev_y)))\n",
    "\n",
    "        dev_predictions = model.predict(x_dev_reduced)\n",
    "        dev_residuals = dev_predictions - JDev_y\n",
    "        train_predictions = model.predict(xtrain_reduced)\n",
    "        train_residuals = train_predictions - JTrain_y\n",
    "        print(f'train residuals: {np.linalg.norm(train_residuals, \"fro\") / np.linalg.norm(JTrain_y, \"fro\")}')\n",
    "        print(f'dev residuals: {np.linalg.norm(dev_residuals, \"fro\") / np.linalg.norm(JDev_y, \"fro\")}')\n",
    "        print('\\n')\n",
    "\n",
    "\n",
    "    #create a plot of a random in the training set\n",
    "    \n",
    "    random_index = np.random.randint(0, 26)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Training Set Predictions\")\n",
    "    plt.scatter(np.arange(0, len(JTrain_y)), JTrain_y[:, random_index], label=\"True\", alpha=0.5)\n",
    "    plt.scatter(np.arange(0, len(JTrain_y)), model.predict(xtrain_reduced)[:, random_index], label=\"Predicted\", alpha=0.5)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Validation Set Predictions\")\n",
    "    plt.scatter(np.arange(len(JDev_y)), JDev_y[:, random_index], label=\"True\", alpha=0.5)\n",
    "    plt.scatter(np.arange(len(JDev_y)), model.predict(x_dev_reduced)[:, random_index], label=\"Predicted\", alpha=0.5)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    #avg_model = np.mean(all_models, axis=0)  # Averaging models might not be the best idea in either NN or Linear model since the model could be converging to two different local minima in the objective function space\n",
    "    avg_train_error = -1 #np.mean(all_relative_errors_training)\n",
    "    avg_val_error = -1 #np.mean(all_relative_errors_validation)\n",
    "    avg_loss_training = np.mean(all_loss_training,axis=0)\n",
    "    avg_loss_validation = np.mean(all_loss_validation,axis=0)\n",
    "\n",
    "    print(f'predictive dev set:{model.predict(x_dev_reduced)[:, random_index]}')\n",
    "    print(f'actual dev set:{JDev_y[:, random_index]}')\n",
    "\n",
    "    print(f'sample predictive train set:{model.predict(xtrain_reduced)[:, random_index]}')\n",
    "    print(f'sample actual train set:{JTrain_y[:, random_index]}')\n",
    "\n",
    "    return all_models, all_relative_errors_training, all_relative_errors_validation, all_loss_training, all_loss_validation, avg_train_error, avg_val_error, avg_loss_training, avg_loss_validation\n",
    "\n",
    "######################\n",
    "    all_relative_errors_training = []\n",
    "    all_relative_errors_validation = []\n",
    "    all_models = []\n",
    "\n",
    "    for train_index, val_index in kfold.split(data):\n",
    "        X_train, X_val = data[train_index], data[val_index]\n",
    "\n",
    "        JTrain_x = X_train[:, selected_indices]\n",
    "        JTrain_y = X_train[:, complement_indices]\n",
    "        JDev_x = X_val[:, selected_indices]\n",
    "        JDev_y = X_val[:, complement_indices]\n",
    "\n",
    "        model = train_model(JTrain_x, JTrain_y, k)\n",
    "        train_relative_error = evaluate_model(model, JTrain_x, JTrain_y)\n",
    "        val_relative_error = evaluate_model(model, JDev_x, JDev_y)\n",
    "\n",
    "        all_models.append(model)\n",
    "        all_relative_errors_training.append(train_relative_error)\n",
    "        all_relative_errors_validation.append(val_relative_error)\n",
    "\n",
    "    avg_model = np.mean(all_models, axis=0)  # Average model coefficients\n",
    "    avg_train_error = np.mean(all_relative_errors_training)\n",
    "    avg_val_error = np.mean(all_relative_errors_validation)\n",
    "\n",
    "    return avg_model, avg_train_error, avg_val_error\n",
    "\n",
    "# Now we can run the cross-validation routine first with n_splits=10\n",
    "all_models, all_relative_errors_training, all_relative_errors_validation, all_loss_training, all_loss_validation, avg_train_error, avg_val_error, avg_loss_training, avg_loss_validation = cross_validate_model(train_dataset_full, selected_indices, complement_indices, n_splits=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30a14410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.]\n",
      " [2.]\n",
      " [2.]]\n"
     ]
    }
   ],
   "source": [
    "# Let's plot some results\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fold_number = np.arange(0, len(all_relative_errors_training))\n",
    "# Plot training and validation errors\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(fold_number, all_relative_errors_training, label='Training Error')\n",
    "plt.scatter(fold_number, all_relative_errors_validation, label='Validation Error')\n",
    "plt.title('Relative Errors')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Relative Error')\n",
    "plt.legend()\n",
    "\n",
    "# Plot training and validation losses\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(fold_number, all_loss_training, label='Training Loss')\n",
    "plt.scatter(fold_number, all_loss_validation, label='Validation Loss')\n",
    "plt.title('Losses')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(np.ones((3, 1))*2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
